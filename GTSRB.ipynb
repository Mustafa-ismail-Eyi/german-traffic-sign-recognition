{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GTSRB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1lPN6Y9REExgSh1q417gB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaimadoglu/german-traffic-sign-recognition/blob/isaWindows/GTSRB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6RyRtkSW2c_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Colab library to upload files to notebook\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_eGxqZPW7ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Kaggle library\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6z4Dy_697uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx7iLruw-CZw",
        "colab_type": "code",
        "outputId": "a3643f20-7019-4bdc-fc08-1f101bd30b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# ls\n",
        "print(os.getcwd())\n",
        "print(os.listdir('../root'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "['.profile', '.bashrc', '.kaggle', '.ipython', '.config', '.keras', '.cache', '.local', '.node-gyp', '.npm', '.jupyter', '.gsutil']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pw3gX0M9rud",
        "colab_type": "code",
        "outputId": "33415301-6ef6-498f-8d2c-cf67936ad431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "os.mkdir('/root/.kaggle')\n",
        "os.chdir('/root/.kaggle')\n",
        "print(os.getcwd())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f5ff63832e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/.kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/.kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/root/.kaggle'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84cOgAQSAlA4",
        "colab_type": "code",
        "outputId": "c2a4c9be-1eac-4b61-90a8-981d59b2c4f7",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Upload kaggle API key file\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7eb6ce58-1cac-4135-b70a-04bd2a6550f5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7eb6ce58-1cac-4135-b70a-04bd2a6550f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cepc436RAsgJ",
        "colab_type": "code",
        "outputId": "b7cf159c-3213-424e-d935-36f1a2dec1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "os.chdir('/content')\n",
        "print(os.getcwd())\n",
        "print(os.listdir('./'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "['.config', 'meta', 'train', 'gtsrb-german-traffic-sign.zip', 'Train.csv', 'kaggle.json', 'Meta', 'Train', 'Meta.csv', 'Test.csv', 'Test', 'test', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wr1jQdRAzG5",
        "colab_type": "code",
        "outputId": "1cf462e3-9ef8-4793-db3b-a9fb81b968c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
        "print(os.getcwd())\n",
        "print(os.listdir('./'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "gtsrb-german-traffic-sign.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "/content\n",
            "['.config', 'meta', 'train', 'gtsrb-german-traffic-sign.zip', 'Train.csv', 'kaggle.json', 'Meta', 'Train', 'Meta.csv', 'Test.csv', 'Test', 'test', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgINWMeqCwbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKohHTE7EHyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zipref = zipfile.ZipFile('gtsrb-german-traffic-sign.zip', 'r')\n",
        "zipref.extractall()\n",
        "zipref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xeY4wC1ENVG",
        "colab_type": "code",
        "outputId": "6bc9a3d9-ceb8-4569-bfec-b40b6dff2688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(os.getcwd())\n",
        "print(os.listdir('./'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "['.config', 'meta', 'train', 'gtsrb-german-traffic-sign.zip', 'Train.csv', 'kaggle.json', 'Meta', 'Train', 'Meta.csv', 'Test.csv', 'Test', 'test', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01mcSKau-il0",
        "colab_type": "text"
      },
      "source": [
        "# **Training Part**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruL8M9pvAt7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "fc920d66-b017-42eb-d519-1da8738e8618"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install tensorflow"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (45.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgLM1P3cBImT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ec5a69ca-fcf9-4281-b8d5-269e362d2ada"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKBqYm9QEYt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "29428e07-5b9c-4920-b075-105f5fbd7973"
      },
      "source": [
        "import cv2\n",
        "# Pillow modulu de OpenCV gibi, basit bir goruntu isleme modulu\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "print(\"Tensorflow Version Should be 2.1: \", tf.__version__)\n",
        "print(\"Keras Version: \", keras.__version__)\n",
        "\n",
        "# Bunlar neural network kurulurken kullaniliyor\n",
        "from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, Dropout, Dense\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# makine ogrenmesinde train ve test datalarini ayiran fonksiyon\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version Should be 2.1:  2.1.0\n",
            "Keras Version:  2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fekiajXi-rqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "outputId": "13a39527-4176-4367-cd52-bd3fcd0b3079"
      },
      "source": [
        "# Reading the input images and putting them into a numpy array\n",
        "data=[]\n",
        "labels=[]\n",
        "\n",
        "# image size'leri 30x30 seklinde kucultmek icin kullanacagiz.\n",
        "height = 30\n",
        "width = 30\n",
        "# RGB icin\n",
        "channels = 3\n",
        "# sinif sayisi\n",
        "num_classes = 43\n",
        "\n",
        "# neural network input katmani icin??\n",
        "n_inputs = height * width*channels\n",
        "\n",
        "# NOT ALALIM\n",
        "for i in range(num_classes) :\n",
        "    path = \"./train/{0}/\".format(i)\n",
        "    print(path)\n",
        "    Class=os.listdir(path)\n",
        "    \n",
        "    # For dongusu ile i'inci class'taki fotograflarin uzerinden geciyor.\n",
        "    for a in Class:\n",
        "        try:\n",
        "            image=cv2.imread(path+a) # siradaki image'i imread ile okuyor.\n",
        "            image_from_array = Image.fromarray(image, 'RGB')  # ???? https://pillow.readthedocs.io/en/3.1.x/reference/Image.html\n",
        "            size_image = image_from_array.resize((height, width))\n",
        "            # image'lar data list'ine numpy array olarak append ediliyor.\n",
        "            data.append(np.array(size_image))\n",
        "            labels.append(i) # etiketler '0, 1, 2, 3, .. ,42' seklinde\n",
        "        except AttributeError:\n",
        "            print(\"Error! goruntuyu alamadik.\")\n",
        "            \n",
        "x_train=np.array(data)\n",
        "# Her bir piksel 0-255 araliginda deger aliyor ya. Ben bu degerleri 0-1 araligina normalize etmek istersem ne yaparim? 255'e bolerim.\n",
        "x_train= x_train/255.0\n",
        "\n",
        "y_train=np.array(labels)\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, num_classes) # Using one hot encoding"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./train/0/\n",
            "./train/1/\n",
            "./train/2/\n",
            "./train/3/\n",
            "./train/4/\n",
            "./train/5/\n",
            "./train/6/\n",
            "./train/7/\n",
            "./train/8/\n",
            "./train/9/\n",
            "./train/10/\n",
            "./train/11/\n",
            "./train/12/\n",
            "./train/13/\n",
            "./train/14/\n",
            "./train/15/\n",
            "./train/16/\n",
            "./train/17/\n",
            "./train/18/\n",
            "./train/19/\n",
            "./train/20/\n",
            "./train/21/\n",
            "./train/22/\n",
            "./train/23/\n",
            "./train/24/\n",
            "./train/25/\n",
            "./train/26/\n",
            "./train/27/\n",
            "./train/28/\n",
            "./train/29/\n",
            "./train/30/\n",
            "./train/31/\n",
            "./train/32/\n",
            "./train/33/\n",
            "./train/34/\n",
            "./train/35/\n",
            "./train/36/\n",
            "./train/37/\n",
            "./train/38/\n",
            "./train/39/\n",
            "./train/40/\n",
            "./train/41/\n",
            "./train/42/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd4fCNzIBpFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "67500448-6ae1-4b9c-da7b-96017cbda371"
      },
      "source": [
        "# Split Data\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X'ler veri, Y'ler label\n",
        "X_train,X_valid,Y_train,Y_valid = train_test_split(x_train,y_train,test_size = 0.3,random_state=0) # X_valid = X_test olarak dusunebiliriz\n",
        "print(\"Train :\", X_train.shape)\n",
        "print(\"Valid :\", X_valid.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train : (27446, 30, 30, 3)\n",
            "Valid : (11763, 30, 30, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXDnmSDAB7hF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "756f3642-99fd-4947-f7d6-2f8171d34db8"
      },
      "source": [
        "# Show Train images \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_images(images, labels, amount):\n",
        "    for i in range(amount):\n",
        "        index = int(random.random() * len(images))\n",
        "        plt.axis('off')\n",
        "        plt.imshow(images[index])\n",
        "        plt.show()       \n",
        "        print(\"Size of this image is \" + str(images[index].shape))\n",
        "        print(\"Class of the image is \" + str(labels[index]))\n",
        "\n",
        "print(\"Train images\")\n",
        "show_images(X_train, Y_train, 3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXhnLtaQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Size of this image is (30, 30, 3)\n",
            "Class of the image is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Size of this image is (30, 30, 3)\n",
            "Class of the image is [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxeY0Jig2pzFBsTmNCcr/Azf9+OPN7dGXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Size of this image is (30, 30, 3)\n",
            "Class of the image is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtO4BKB_B-PF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "10eed7b1-66d7-4abf-f637-1b0e949e5ccd"
      },
      "source": [
        "# Build Model\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=X_train.shape[1:])) # input layer + convolution layer\n",
        "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(num_classes, activation='softmax')) # class'i belirleyen layer\n",
        "\n",
        "model.summary() # ???"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               803072    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 43)                11051     \n",
            "=================================================================\n",
            "Total params: 879,691\n",
            "Trainable params: 879,691\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZAx-K7TCCGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile Model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLhpDglCCEWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "58215e1b-dd5c-48c0-e69e-f370ad7fe0ef"
      },
      "source": [
        "# Train Model\n",
        "epochs = 10\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), batch_size=32, epochs=epochs,verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 27446 samples, validate on 11763 samples\n",
            "Epoch 1/10\n",
            "27446/27446 [==============================] - 142s 5ms/sample - loss: 1.5726 - accuracy: 0.5517 - val_loss: 0.2591 - val_accuracy: 0.9268\n",
            "Epoch 2/10\n",
            "27446/27446 [==============================] - 141s 5ms/sample - loss: 0.3571 - accuracy: 0.8859 - val_loss: 0.0908 - val_accuracy: 0.9749\n",
            "Epoch 3/10\n",
            "20096/27446 [====================>.........] - ETA: 34s - loss: 0.2101 - accuracy: 0.9356"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-2054193ac1fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QYD4LslCGDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the accuracy and the loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGUpEmMmCKAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting Test data \n",
        "y_test=pd.read_csv(\"../input/gtsrb-german-traffic-sign/Test.csv\")\n",
        "labels=y_test['Path'].as_matrix()\n",
        "y_test=y_test['ClassId'].values\n",
        "\n",
        "data=[]\n",
        "\n",
        "for f in labels:\n",
        "    image=cv2.imread('../input/gtsrb-german-traffic-sign/test/'+f.replace('Test/', ''))\n",
        "    image_from_array = Image.fromarray(image, 'RGB')\n",
        "    size_image = image_from_array.resize((height, width))\n",
        "    data.append(np.array(size_image))\n",
        "\n",
        "X_test=np.array(data)\n",
        "X_test = X_test.astype('float32')/255  \n",
        "pred = model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvOomJHhCOAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Accuracy with the test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72N3JmrbCS7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"pred: \", pred, \" Type: \", type(pred), \" shape: \", pred.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h9G5V5WCU8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"X_test: \", X_test, \" Type: \", type(X_test), \" shape: \", X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE2TgDQ1CZGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_in = 1\n",
        "second_in = 2\n",
        "class_of_prediction = model.predict_classes(X_test[first_in:second_in])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZRccJBcCars",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_of_prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAGQkGjlCc4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sinif = 1\n",
        "if(class_of_prediction == sinif):\n",
        "    print(\"Birinci Sinif\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}